NEWS SITES APIS
Nexis Solutions ,Webit,Robust Foundation API ,Article Search new york times,msnbc entities api& documents apis
BBC Platform api

SENTIMENT ANALYSIS PAPERS

[Pang, B., & Lee, L. (2008). Opinion Mining and Sentiment Analysis.
 Foundations and Trends® in Information Retrieval, 2(1–2), 1–135. doi:10.1561/1500000011]
url:https://sci-hub.se/10.1561/1500000011

Notes
  "One set of problems share the following general character:
  given an opinionated piece of text, wherein it is assumed that the overall opin-ion in it is about one single issue or item,
  classify the opinion as falling under one of two opposing sentiment polarities,
  or locate its position on the continuum between these two polarities. "
  "sentiment polarity classification or polarity classification"

27  M. Bansal, C. Cardie, and L. Lee,
  “The power of negative thinking: Exploiting label disagreement in the min-cut classification framework”
294   M. Thomas, B. Pang, and L. Lee,
    “Get out the vote: Determining support oropposition from congressional floor-debate transcripts,”
112   G.  Grefenstette,  Y.  Qu,  J.  G.  Shanahan,  and  D.  A.  Evans,
   “Coupling niche  browsers  and  affect  analysis  for  an  opinion  mining  application,”.
178 M. Laver, K. Benoit, and J. Garry,
    “Extracting policy positions from polit-ical texts using words as data,

202  L. W. Martin and G. Vanberg,
 “A robust transformation procedure for inter-preting political text

  [27, 294] papers that might be useful  a political speech is in support of or opposition to the issue under debate
  "Grefenstette et al. [112] experimented with determining the political orientation of websites essentially by classifying the concate-nation
   of all the documents found on that site. We group this type of work under the heading of “viewpoints and perspectives,”
   and include under this rubric work on classifying texts as liberal, conservative, lib-ertarian,
   etc. [219], placing texts along an ideological scale [178, 202],or representing Israeli versus Palestinian viewpoints [186, 187]."
   Technicue-Part of speech tagging and mostly focusing on the presence adjectives

"the accuracy of sentiment classification can be influenced by topic. Read [249] finds standard machine learning techniques for opinion analysis
 to be both domain-dependent (with domains ranging from movie reviews to newswire articles) and temporally dependent
  (based on datasets spanning different ranges of time periods but written at least one year apart)."

134  M. Hurst and K. Nigam,
“Retrieving topical sentiments from online document collections

  "One  approach  to  integrating  sentiment  and  topic  when  one  is looking for opinionated documents on a particular user-specified topic  is to
  simply first perform one analysis pass, say for topic, and  then ana-lyze the results with respect to sentiment [134].
  (See Sebastiani [263]for a survey of machine learning approaches to topic-based text catego-rization.)
  Such a two-pass approach was taken by a number of systems at the TREC Blog track in 2006, according to Ounis et al. [227], andothers [234].
  Alternatively, one may jointly model topic and sentiment simultaneously [84, 206], or treat one as a prior for the other [85]."


"As is well known, opinions matter a great deal in politics. Some work has focused on understanding what voters are thinking [83, 110,126, 178, 219], whereas other projects have as a long term goal the clar-ification of politicians’ positions, such as what public figures support oroppose, to enhance the quality of information that voters have accessto [27, 111, 294].Sentiment analysis has specifically been proposed as a key enablingtechnology in eRulemaking, allowing the automatic analysis of the opin-ions that people submit about pending policy or government-regulation proposals [50, 175, 271]"


Feldman, R. (2013). Techniques and applications for sentiment analysis. Communications of the ACM, 56(4), 82. doi:10.1145/2436256.2436274

Notes
General  Inquirer  lexicon;33  http://www.wjh.harvard.edu/~inquirer/    spread-sheet_guide.htm.˲Sentiment    lexicon;13    http://www.cs.uic.edu/~liub/FBS/sentiment-analy-sis.html.˲MPQA   subjectivity   lexicon;38   http://www.cs.pitt.edu/mpqa/subj_lexicon.html.˲SentiWordNet;6     http://sentiword-net.isti.cnr.it/.˲Emotion     lexicon;23     http://www.purl.org/net/emolex.˲Financial Sentiment Lexicons (suit-ed  for  the  determination  of  the  senti-ment  of  financial  documents);22  http://nd.edu/~mcdonald/Word_Lists.html.



Cambria, E., Schuller, B., Xia, Y., & Havasi, C. (2013). New Avenues in Opinion Mining and Sentiment Analysis

Notes


Tools: SenticNet  (http://sentic.net),  Luminoso  (http://luminoso.com),  Factiva  (http://dowjones.com/factiva),
Attensity  (http://attensity.com), and Converseon (http://converseon.com)




Young, L., & Soroka, S. (2012). Affective News: The Automated Coding of Sentiment in Political Texts. Political Communication

Notes
Lexicoder Sentiment Dictionary
ANOVA testing
"There are now numerous machine-readable dictionaries available for research,
 but they vary widely with respect to categories and scope of coverage.
  They include, for example, the following: from political science ,the GI (Stone et al., 1966);
   from communication, DICTION (Hart, 2000a); from psychology, Linguistic Inquiry and Word Count (LIWC)
   (Pennebaker, Francis, & Booth,2001), the Regressive Imagery Dictionary (RID) (Martindale, 1975, 1990),
    and TAS/C(Mergenthaler, 1996, 2008); from behavioral science,
     Affective Norms for English Words(ANEW) (Bradley & Lang, 1999); from literature,
     Whissell’s Dictionary of Affect in Language (DAL) (Whissell, 1989);
     from linguistics, WordNet-Affect (WNA) (Strapparava& Valitutti, 2004);
      and from computational linguistics, Turney and Littman’s (2003) point-wise mutual (PMI) information wordlist,
       as well as the ubiquitous Roget’s Thesaurus(hereafter Roget’s) (Roget, 1911)"
"Indeed, notwithstanding concerns about ambiguity, most dictionaries are generated for a particular purpose or genre of text,
 and as a consequence tend to be temporally and corpo-rally specific.
 For instance, TAS/C was created to measure emotional tone and abstraction in psychotherapy sessions;
  DAL was developed to analyze the affective content of poetry and literature;
   RID was designed to distinguish between primordial and conceptual thinking;
   and DICTION was developed primarily to understand the rhetoric of speechmakers.
   Closest to our purposes are GI and LIWC, both of which were developed to analyze various affect categories in political texts"
(on the LSD dataset)
"Thus, tone should be considered acomposite measure of (a) the relative negativity of the actual events or issues being covered and
 (b) the opinions and attitudes of newsmakers about those events and issues"
"Simply comparing results across dictionaries is not enough, of course—we need to compare them with some other externally valid analysis,
specifically human-coded content-analytic data. We do so here using a body of data coded by three trained human coders.
The data include 900 articles from the New York Times.
Four hundred fifty were randomly drawn from an existing database on all economics stories published in the Times from 1988–2008.
The other 450 were randomly drawn from a previously topic-coded database of all front-page stories in the Times from 2007–2009.
 In this case, we drew 150 randomly from within each of three topic categories: environment, foreign affairs, and crime.
 The selection of these topics provides, we believe, a good basis for an initial test of theLSD.
  We have chosen a range of domestic and international policy issues;
  we also intentionally use issues that have seen a particularly large amount of attention in the political communication literature."
